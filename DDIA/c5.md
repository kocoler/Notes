## Replication

Goal:
- reduce latency
- increase availability
- increase throughput
- (scalability)

Three popular algorithms:
- single leader
  requires all writes to go through a single node(suitable for read-more and write-less workloads)
- multi leader
- leaderless

chain replication

### Leaders and followers

#### setup new follower

- snapshot
- send snapshot to new follower
- follower ask the new data since the snapshot
- process
- catch up

#### handling node outages

- follower failure: catch-up recovery
  local logs -> get data since last transitions -> catch-up
- leader failure: failover
  promote new leader

#### implementation of replication logs

- statement-based replication
  just logs every write request -> transmit to followers
  problems:
    - nondeterministic function
    - some ops depends on current state(like auto-increment)
    - nondeterministic side effects
  solutions:
    - make nondeterministic factors deterministic(fixed number)
  dbs:
    - mysql(<= 5.1)
    - voltDB

- WAL shipping
  problems:
    - some db WAL closely coupled with storage engine(upgrade may cause downtime, otherwise won't)

- Logical log replication
  use different log structure to store log(not original WAL), allows the replication log to be decoupled from storage engine.
  more easily to keep backward compatible.

- Trigger-based replication


### Problems with replication lag
  "eventually consistent"

#### Reading your own writes
  - if could modified -> read from leader(eg. own profile and others profile)
  - if just modified -> read from leader, others read from followers(also could calculate lag of the followers, don't queries on followers which more than one minute behind)
  - client use logical timestamp to read data
  you also should consider user use multi-device
  - centralized storage metadata
  - route all requests to the same datacenter

#### Monotonic read
  It’s a lesser guarantee than strong consistency, but a stronger guarantee than eventual consistency.

  solution:
  - always read from the same replica

#### Consistent Prefix Reads
  This guarantee says that if a sequence of writes happens in a certain order, then anyone reading those writes will see them appear in the same order.

#### Solutions for Replication Lag
  Thinking about how the application behaves if the replication lag increases to several minutes or even hours.
  If answer if not: change to provide a stronger guarantee.

  > This is why transactions exist: they are a way for a database to provide stronger guarantees so that the application can be simpler.

### Multi-Leader replication

> Leader-based replication has one major downside: there is only one leader, and all writes must go through it.

Mainly used in multi-datacenter environment.

![图 1](https://s2.loli.net/2022/05/03/tlX94j75Lxy6wIk.png)  

- performance will be better(asynchronously to other datacenters)
- tolerance improved(outage && network)

Use cases:
1. multi-datacenter operation
2. client with offline operation
3. collaborative editing

Synchronous versus asynchronous conflict detection: prefer to use asynchronous

Conflict avoidance: route to same datacenter

Converging toward a consistent state: unique ID, replica priority, merge the values, let application decide

Custom conflict resolution logic:
- on write
  handle the conflict, mainly background
- on read
  just record the conflicts, and promote to users


**\*\* ??**
**Automatic Conflict Resolution:**
still yong on db filed
- conflict-free replicated datatypes(CRDTs)
- mergeable persistent data structures 
- operational transformation


#### Multi-Leader Replication Topologies

![图 2](https://s2.loli.net/2022/05/03/4j1rJR3sQTtoaMz.png)  


MySQL use [a]
[b] is like a tree
[c] more suitable for fault tolerance, but may cause “overtake” situations(unordered messages)

### Leaderless Replication

Dynamo-style: Amazon Dynamo(not DynamoDB ...), Riak, Cassandra, and Voldemort.(none relational databases)

Ways:
- the client directly sends its writes to several replicas
- a coordinator node does this on behalf of the client
  coordinator does not enforce a particular ordering of writes

#### Writing to the Database When a Node Is Down

read values from all servers, and assert the latest value based on the version number.

#### Read repair and anti-entropy

when a node come back
- read repair
  client write back the latest value to the stale node
- anti-entropy repair
  background process to detect and repair the stale node(unordered)

#### Quorums for reading and writing

> if there are n replicas, every write must be confirmed by w nodes to be considered successful, and we must query at least r nodes for each read.
> **w + r > n**

w, r, n could variable

**There may be more than n nodes in the cluster, but any given value is stored only on n nodes. This allows the dataset to be partitioned.**

send requests to n replicas in parallel, and w/r determine how many nodes wait for

#### Limitations of Quorum Consistency

edge cases:
- no overlap writer and reader
- write concurrently
- write concurrently with read
- how success writes rollback
- new node recover from old node(latest node will fall down w)
- timing(** ?)

Monitoring staleness: better have record in metrics(filed, not monitoring metrics, cause leaderless system could't be monitored in such way ...)

#### Sloppy Quorums and Hinted Handoff

write to other nodes other than the n nodes

when original node is recover, send back -> "hinted handoff"

Multi-datacenter operation: just like single.

#### Detecting Concurrent Writes

- Last write wins (discarding concurrent writes)
  discard any writes with an earlier timestamp

- The “happens-before” relationship and concurrency
  we simply call two operations concurrent if they are both unaware of each other
- Capturing the happens-before relationship
  typical version
- Merging concurrently written values
  `siblings` means two concurrent records, which we have to merge
  especially for deleted operations
- Version vectors
  for multi replicas:
  we need to use a version number per replica as well as per key, this called a version vector(aka, causal context)
